# Real-ESRGAN Video Super-Resolution (ONNX Inference)

> ğŸš€ A lightweight, GPU-accelerated video upscaling tool based on Real-ESRGAN and ONNX runtime.  
> ğŸ¬ Input: 720p video â†’ Output: 4K super-resolved video.

---

## ğŸ§  Features

- âœ… Supports **ONNXRuntime** inference with **CUDA** acceleration.
- ğŸ“¦ No need to install PyTorch or original Real-ESRGAN dependencies.
- ğŸ¥ Converts videos frame-by-frame with upscaling factor **x4**.
- ğŸ–¥ï¸ Tested on 720p â†’ 4K, ~9 seconds per frame on CPU, real-time possible with GPU.

---

## ğŸ“ Directory Structure
Real-ESRGAN-SR/
â”œâ”€â”€ RealESRGAN_x4plus-dynamic.onnx    # ONNX model file (x4 upscaling)
â”œâ”€â”€ video_sr.py                       # Super-resolution script
â”œâ”€â”€ requirements.txt                  # Lightweight dependency list
â””â”€â”€ README.md                         # This file
---

## ğŸ”§ Installation

Create and activate a Python environment (optional but recommended):

```bash
python -m venv venv
source venv/bin/activate  # Or venv\Scripts\activate on Windows

Then install dependencies:
pip install -r requirements.txt

â–¶ï¸ Usage
Put your input video (e.g., input_720p.mp4) in the project directory, then run:
Output: output_4k.mp4 in the same folder.

The script:
	â€¢	Loads the ONNX model
	â€¢	Reads input video frame by frame
	â€¢	Performs x4 super-resolution
	â€¢	Writes the output as 4K video

â¸»

ğŸ“· Example

Input:


Output (Super-resolved):


(Replace with your own before/after images if you want)

â¸»

ğŸ’¬ Notes
	â€¢	The current ONNX model (RealESRGAN_x4plus-dynamic.onnx) must support dynamic input shape.
	â€¢	Make sure your GPU supports CUDA and is recognized by ONNXRuntime.
	â€¢	Do not include model weights > 100MB on GitHub (use Git LFS if needed).

â¸»

ğŸ“œ License

This project is adapted from Real-ESRGAN, which is released under the BSD-3-Clause License.

â¸»

ğŸ™‹â€â™‚ï¸ Contact

Maintainer: tutuyygit
Pull requests and issues welcome!